{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-11-10T16:24:04.525886Z",
     "start_time": "2023-11-10T16:24:04.518499Z"
    }
   },
   "outputs": [],
   "source": [
    "import split_data, create_corpus, read_corpus, train, predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "def log(text: str, inverse: bool = False):\n",
    "    l = 100\n",
    "    out = [f\"{text:^{l}}\", \"-\" * l]\n",
    "    if inverse:\n",
    "        out.reverse()\n",
    "\n",
    "    print(\"\\n\")\n",
    "    print(out[0])\n",
    "    print(out[1])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-10T16:24:05.001825Z",
     "start_time": "2023-11-10T16:24:04.999757Z"
    }
   },
   "id": "32d8013b60bc0da7"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "                                           Reading corpus                                           \n",
      "----------------------------------------------------------------------------------------------------\n",
      "2023-11-10 13:24:05,459 Reading data from /Users/federicotanzi/sandbox/Yoda-NER/data/corpus\n",
      "2023-11-10 13:24:05,460 Train: /Users/federicotanzi/sandbox/Yoda-NER/data/corpus/train.txt\n",
      "2023-11-10 13:24:05,460 Dev: /Users/federicotanzi/sandbox/Yoda-NER/data/corpus/val.txt\n",
      "2023-11-10 13:24:05,460 Test: /Users/federicotanzi/sandbox/Yoda-NER/data/corpus/test.txt\n"
     ]
    }
   ],
   "source": [
    "log(\"Reading corpus\")\n",
    "corpus = read_corpus.main()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-10T16:24:13.954174Z",
     "start_time": "2023-11-10T16:24:05.460528Z"
    }
   },
   "id": "177ea05eb942302e"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-11-10 13:24:21,050 Computing label dictionary. Progress:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "60000it [00:00, 104707.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-11-10 13:24:21,681 Dictionary created for label 'ner' with 4 values: size (seen 68915 times), brand (seen 47046 times), color (seen 20887 times)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[6], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[43mtrain\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmain\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcorpus\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/sandbox/Yoda-NER/src/train.py:125\u001B[0m, in \u001B[0;36mmain\u001B[0;34m(corpus)\u001B[0m\n\u001B[1;32m    121\u001B[0m TRANSFORMER_ONLY \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m\n\u001B[1;32m    123\u001B[0m label_dict \u001B[38;5;241m=\u001B[39m get_corpus_dict(corpus, LABEL_TYPE)\n\u001B[0;32m--> 125\u001B[0m embeddings \u001B[38;5;241m=\u001B[39m \u001B[43mget_embeddings\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    126\u001B[0m stack_embedding \u001B[38;5;241m=\u001B[39m (\n\u001B[1;32m    127\u001B[0m     embeddings[\u001B[38;5;241m0\u001B[39m] \u001B[38;5;28;01mif\u001B[39;00m TRANSFORMER_ONLY \u001B[38;5;28;01melse\u001B[39;00m get_embedding_stack(embeddings)\n\u001B[1;32m    128\u001B[0m )\n\u001B[1;32m    129\u001B[0m tagger \u001B[38;5;241m=\u001B[39m get_sequence_tagger(stack_embedding, label_dict, LABEL_TYPE)\n",
      "File \u001B[0;32m~/sandbox/Yoda-NER/src/train.py:88\u001B[0m, in \u001B[0;36mget_embeddings\u001B[0;34m()\u001B[0m\n\u001B[1;32m     86\u001B[0m flair_forward_embedding \u001B[38;5;241m=\u001B[39m FlairEmbeddings(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mes-forward\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m     87\u001B[0m flair_backward_embedding \u001B[38;5;241m=\u001B[39m FlairEmbeddings(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mes-backward\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m---> 88\u001B[0m word_embedding \u001B[38;5;241m=\u001B[39m \u001B[43mWordEmbeddings\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mes-crawl\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m     90\u001B[0m sm_flair_forward_embedding \u001B[38;5;241m=\u001B[39m FlairEmbeddings(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mes-forward-fast\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m     91\u001B[0m sm_flair_backward_embedding \u001B[38;5;241m=\u001B[39m FlairEmbeddings(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mes-backward-fast\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/ner/lib/python3.9/site-packages/flair/embeddings/token.py:217\u001B[0m, in \u001B[0;36mWordEmbeddings.__init__\u001B[0;34m(self, embeddings, field, fine_tune, force_cpu, stable)\u001B[0m\n\u001B[1;32m    213\u001B[0m     precomputed_word_embeddings \u001B[38;5;241m=\u001B[39m gensim\u001B[38;5;241m.\u001B[39mmodels\u001B[38;5;241m.\u001B[39mKeyedVectors\u001B[38;5;241m.\u001B[39mload_word2vec_format(\n\u001B[1;32m    214\u001B[0m         \u001B[38;5;28mstr\u001B[39m(embeddings_path), binary\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[1;32m    215\u001B[0m     )\n\u001B[1;32m    216\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m--> 217\u001B[0m     precomputed_word_embeddings \u001B[38;5;241m=\u001B[39m \u001B[43mgensim\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmodels\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mKeyedVectors\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mload\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mstr\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43membeddings_path\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    219\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m__embedding_length: \u001B[38;5;28mint\u001B[39m \u001B[38;5;241m=\u001B[39m precomputed_word_embeddings\u001B[38;5;241m.\u001B[39mvector_size\n\u001B[1;32m    221\u001B[0m vectors \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mrow_stack(\n\u001B[1;32m    222\u001B[0m     (\n\u001B[1;32m    223\u001B[0m         precomputed_word_embeddings\u001B[38;5;241m.\u001B[39mvectors,\n\u001B[1;32m    224\u001B[0m         np\u001B[38;5;241m.\u001B[39mzeros(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m__embedding_length, dtype\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mfloat\u001B[39m\u001B[38;5;124m\"\u001B[39m),\n\u001B[1;32m    225\u001B[0m     )\n\u001B[1;32m    226\u001B[0m )\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/ner/lib/python3.9/site-packages/gensim/utils.py:487\u001B[0m, in \u001B[0;36mSaveLoad.load\u001B[0;34m(cls, fname, mmap)\u001B[0m\n\u001B[1;32m    484\u001B[0m compress, subname \u001B[38;5;241m=\u001B[39m SaveLoad\u001B[38;5;241m.\u001B[39m_adapt_by_suffix(fname)\n\u001B[1;32m    486\u001B[0m obj \u001B[38;5;241m=\u001B[39m unpickle(fname)\n\u001B[0;32m--> 487\u001B[0m \u001B[43mobj\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_load_specials\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfname\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmmap\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcompress\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msubname\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    488\u001B[0m obj\u001B[38;5;241m.\u001B[39madd_lifecycle_event(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mloaded\u001B[39m\u001B[38;5;124m\"\u001B[39m, fname\u001B[38;5;241m=\u001B[39mfname)\n\u001B[1;32m    489\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m obj\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/ner/lib/python3.9/site-packages/gensim/models/keyedvectors.py:263\u001B[0m, in \u001B[0;36mKeyedVectors._load_specials\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m    261\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_load_specials\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[1;32m    262\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Handle special requirements of `.load()` protocol, usually up-converting older versions.\"\"\"\u001B[39;00m\n\u001B[0;32m--> 263\u001B[0m     \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mKeyedVectors\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_load_specials\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    264\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdoctags\u001B[39m\u001B[38;5;124m'\u001B[39m):\n\u001B[1;32m    265\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_upconvert_old_d2vkv()\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/ner/lib/python3.9/site-packages/gensim/utils.py:529\u001B[0m, in \u001B[0;36mSaveLoad._load_specials\u001B[0;34m(self, fname, mmap, compress, subname)\u001B[0m\n\u001B[1;32m    527\u001B[0m     val \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mload(subname(fname, attrib))[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mval\u001B[39m\u001B[38;5;124m'\u001B[39m]\n\u001B[1;32m    528\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m--> 529\u001B[0m     val \u001B[38;5;241m=\u001B[39m \u001B[43mnp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mload\u001B[49m\u001B[43m(\u001B[49m\u001B[43msubname\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfname\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mattrib\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmmap_mode\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmmap\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    531\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m ignore_deprecation_warning():\n\u001B[1;32m    532\u001B[0m     \u001B[38;5;28msetattr\u001B[39m(\u001B[38;5;28mself\u001B[39m, attrib, val)\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/ner/lib/python3.9/site-packages/numpy/lib/npyio.py:456\u001B[0m, in \u001B[0;36mload\u001B[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding, max_header_size)\u001B[0m\n\u001B[1;32m    453\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mformat\u001B[39m\u001B[38;5;241m.\u001B[39mopen_memmap(file, mode\u001B[38;5;241m=\u001B[39mmmap_mode,\n\u001B[1;32m    454\u001B[0m                                   max_header_size\u001B[38;5;241m=\u001B[39mmax_header_size)\n\u001B[1;32m    455\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m--> 456\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mformat\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mread_array\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfid\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mallow_pickle\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mallow_pickle\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    457\u001B[0m \u001B[43m                                 \u001B[49m\u001B[43mpickle_kwargs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mpickle_kwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    458\u001B[0m \u001B[43m                                 \u001B[49m\u001B[43mmax_header_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmax_header_size\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    459\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    460\u001B[0m     \u001B[38;5;66;03m# Try a pickle\u001B[39;00m\n\u001B[1;32m    461\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m allow_pickle:\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/ner/lib/python3.9/site-packages/numpy/lib/format.py:809\u001B[0m, in \u001B[0;36mread_array\u001B[0;34m(fp, allow_pickle, pickle_kwargs, max_header_size)\u001B[0m\n\u001B[1;32m    806\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    807\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m isfileobj(fp):\n\u001B[1;32m    808\u001B[0m         \u001B[38;5;66;03m# We can use the fast fromfile() function.\u001B[39;00m\n\u001B[0;32m--> 809\u001B[0m         array \u001B[38;5;241m=\u001B[39m \u001B[43mnumpy\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfromfile\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfp\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdtype\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdtype\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcount\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcount\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    810\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    811\u001B[0m         \u001B[38;5;66;03m# This is not a real file. We have to read it the\u001B[39;00m\n\u001B[1;32m    812\u001B[0m         \u001B[38;5;66;03m# memory-intensive way.\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    820\u001B[0m         \u001B[38;5;66;03m# not correctly instantiate zero-width string dtypes; see\u001B[39;00m\n\u001B[1;32m    821\u001B[0m         \u001B[38;5;66;03m# https://github.com/numpy/numpy/pull/6430\u001B[39;00m\n\u001B[1;32m    822\u001B[0m         array \u001B[38;5;241m=\u001B[39m numpy\u001B[38;5;241m.\u001B[39mndarray(count, dtype\u001B[38;5;241m=\u001B[39mdtype)\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "log(\"Starting trainning\")\n",
    "train.main(corpus)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-10T16:24:25.787626Z",
     "start_time": "2023-11-10T16:24:21.052132Z"
    }
   },
   "id": "d1b06f83c51aee8b"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "log(\"Prediction example\")\n",
    "predict.main(\"BOTAS CHIRUCA GREDOS SUPRA 12 GORE-TEX MARRON 43 Marron\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a806743ea3f62966"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
